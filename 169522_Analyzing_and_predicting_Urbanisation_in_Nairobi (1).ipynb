{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"setup\"></a>\n",
        "# <p style=\"background-color:rgb(64, 96, 143); font-family:calibri; color:white; font-size:50%; font-family:Verdana; text-align:center; border-radius:5px 5px;\">Step 1 | SETUP AND INITIALIZATION</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import libraries you'll need\n",
        "\n",
        "import pandas as pd\n",
        "import geopandas as gpd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler,RobustScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.combine import SMOTETomek\n",
        "from collections import Counter\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, f1_score\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from scipy.stats import randint\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from scipy.stats import loguniform \n",
        "from xgboost import XGBClassifier\n",
        "import joblib\n",
        "import folium\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'venv_name' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: '\"c:/Users/USER/Desktop/Thesis Folder/Ronnie/venv_name/Scripts/python.exe\" -m pip install ipykernel -U --force-reinstall'"
          ]
        }
      ],
      "source": [
        "# Read file from github\n",
        "url = \"https://github.com/baariu/Analyzing-and-Predicting-Urbanization-in-Nairobi-using-GIS-and-Data-Mining-Techniques/raw/refs/heads/main/Spatial%20Data.xlsx\"\n",
        "\n",
        "df = pd.read_excel(url)\n",
        "\n",
        "# Display the first few rows of the dataframe\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"setup\"></a>\n",
        "# <p style=\"background-color:rgb(64, 96, 143); font-family:calibri; color:white; font-size:50%; font-family:Verdana; text-align:center; border-radius:5px 5px;\">Step 2 | DATA EXPLORATION</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ONsJQePtxYZI",
        "outputId": "c9e33875-2e68-4f3a-ef7a-7f2f6b19075b"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'venv_name' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: '\"c:/Users/USER/Desktop/Thesis Folder/Ronnie/venv_name/Scripts/python.exe\" -m pip install ipykernel -U --force-reinstall'"
          ]
        }
      ],
      "source": [
        "# Lets observe the dataset.\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338
        },
        "id": "XNLsNMLmxhkJ",
        "outputId": "b9c30afe-6ffb-400a-b538-a2b2d55f3662"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'venv_name' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: '\"c:/Users/USER/Desktop/Thesis Folder/Ronnie/venv_name/Scripts/python.exe\" -m pip install ipykernel -U --force-reinstall'"
          ]
        }
      ],
      "source": [
        "#Distribution of data. Is the data balanced?\n",
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "vzuGftzsiLMH",
        "outputId": "c18fee4a-a95c-4bea-9370-4e00e10b8ac2"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'venv_name' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: '\"c:/Users/USER/Desktop/Thesis Folder/Ronnie/venv_name/Scripts/python.exe\" -m pip install ipykernel -U --force-reinstall'"
          ]
        }
      ],
      "source": [
        "df[\"change_detection_value\"].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "zLDJcbDRib1r",
        "outputId": "b4fca8ee-8bd2-4d6d-f22f-5b9e7a4a2125"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'venv_name' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: '\"c:/Users/USER/Desktop/Thesis Folder/Ronnie/venv_name/Scripts/python.exe\" -m pip install ipykernel -U --force-reinstall'"
          ]
        }
      ],
      "source": [
        "#Remap this column, to enable its use in some models.  1.0 should become 0.0\n",
        "#2.0 should become 1.0. Models like xgboost only use 0 and 1\n",
        "\n",
        "df['change_detection_value'] = df['change_detection_value'].apply(lambda x: 1 if x == 2 else 0)\n",
        "\n",
        "#Observe the change\n",
        "df[\"change_detection_value\"].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "TOYI5hIyxhbQ",
        "outputId": "41b5079e-a042-4e7e-c1de-39a570d4aaf8"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'venv_name' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: '\"c:/Users/USER/Desktop/Thesis Folder/Ronnie/venv_name/Scripts/python.exe\" -m pip install ipykernel -U --force-reinstall'"
          ]
        }
      ],
      "source": [
        "# The distribution of the dataset further by ploting a histogram of each feature\n",
        "\n",
        "df.hist(figsize=(13,15))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div style=\"border-radius:10px; padding: 15px; background-color: rgb(142, 183, 190); \n",
        "            font-size:110%; text-align:LEFT; width: 95%; color: BLACK;\">\n",
        "\n",
        "\n",
        "## Key Observations\n",
        "- **Inverse Relationship**:\n",
        "  - Lower elevation ↔ Closer to urban infrastructure\n",
        "  - Higher elevation ↔ More remote areas\n",
        "- **Data Distribution**:\n",
        "  - Sparse representation at elevation extremes\n",
        "  - Potential outliers in high-elevation, low-distance points\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xH1TMaOiyk25"
      },
      "source": [
        "<a id=\"setup\"></a>\n",
        "# <p style=\"background-color:rgb(64, 96, 143); font-family:calibri; color:white; font-size:50%; font-family:Verdana; text-align:center; border-radius:5px 5px;\">Step 3 | DATA CLEANING</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 492
        },
        "id": "J8tmM9QQyksE",
        "outputId": "5be33368-618b-43fb-ce46-6ae8ade34d3d"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'venv_name' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: '\"c:/Users/USER/Desktop/Thesis Folder/Ronnie/venv_name/Scripts/python.exe\" -m pip install ipykernel -U --force-reinstall'"
          ]
        }
      ],
      "source": [
        "# Calculate null percentage and add '%' symbol\n",
        "null_percentage = (df.isna().mean() * 100).round(2).astype(str) + '%'\n",
        "\n",
        "# Display results\n",
        "print(\"Null Values (% of Total):\")\n",
        "print(null_percentage)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "vDTJRwfRzGGE"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'venv_name' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: '\"c:/Users/USER/Desktop/Thesis Folder/Ronnie/venv_name/Scripts/python.exe\" -m pip install ipykernel -U --force-reinstall'"
          ]
        }
      ],
      "source": [
        "#Drop 'Distance_to_industrial_Zones(Metres)'\n",
        "df = df.drop('Distance_to_industrial_Zones(Metres)', axis=1)\n",
        "df = df.drop('id', axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TbHtTkm0GzCp"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'venv_name' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: '\"c:/Users/USER/Desktop/Thesis Folder/Ronnie/venv_name/Scripts/python.exe\" -m pip install ipykernel -U --force-reinstall'"
          ]
        }
      ],
      "source": [
        "#Impute the slope column with the median value\n",
        "df['Slope'] = df['Slope'].fillna(df['Slope'].median())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 429
        },
        "id": "MVeBxNODucRi",
        "outputId": "4062ba64-519a-4776-8830-b9557742093f"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'venv_name' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: '\"c:/Users/USER/Desktop/Thesis Folder/Ronnie/venv_name/Scripts/python.exe\" -m pip install ipykernel -U --force-reinstall'"
          ]
        }
      ],
      "source": [
        "#Confirm if any more missing values are left\n",
        "df.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 429
        },
        "id": "-lguKrr8HE1V",
        "outputId": "59ea5cb1-acf9-472d-da45-54c8ab0d32bf"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'venv_name' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: '\"c:/Users/USER/Desktop/Thesis Folder/Ronnie/venv_name/Scripts/python.exe\" -m pip install ipykernel -U --force-reinstall'"
          ]
        }
      ],
      "source": [
        "#Drop the missing values in persons per pixel 1km2\n",
        "df = df.dropna(subset=['persons per  pixel 1km2'])\n",
        "\n",
        "df.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JuMrAnH-p74G"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'venv_name' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: '\"c:/Users/USER/Desktop/Thesis Folder/Ronnie/venv_name/Scripts/python.exe\" -m pip install ipykernel -U --force-reinstall'"
          ]
        }
      ],
      "source": [
        "#Drop road names\n",
        "\n",
        "df = df.drop('Road_Name', axis=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "id": "wDAqVp7YnJCN",
        "outputId": "ddb10ddd-38bb-4aee-bdb0-8b7fffaa068f"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'venv_name' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: '\"c:/Users/USER/Desktop/Thesis Folder/Ronnie/venv_name/Scripts/python.exe\" -m pip install ipykernel -U --force-reinstall'"
          ]
        }
      ],
      "source": [
        "df['change_detection_value'] = df['change_detection_value'].astype(str)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'venv_name' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: '\"c:/Users/USER/Desktop/Thesis Folder/Ronnie/venv_name/Scripts/python.exe\" -m pip install ipykernel -U --force-reinstall'"
          ]
        }
      ],
      "source": [
        "# 1. Define your numerical columns (automatically detected)\n",
        "numerical_cols = df.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
        "\n",
        "# 2. Calculate grid dimensions\n",
        "n_cols = len(numerical_cols)\n",
        "n_rows = (n_cols + 1) // 2  # Round up division\n",
        "\n",
        "# 3. Create the plot with proper sizing\n",
        "plt.figure(figsize=(15, 5*n_rows), facecolor='white')\n",
        "\n",
        "for i, col in enumerate(numerical_cols, 1):\n",
        "    ax = plt.subplot(n_rows, 2, i)\n",
        "    \n",
        "    # Calculate IQR bounds\n",
        "    q1 = df[col].quantile(0.25)\n",
        "    q3 = df[col].quantile(0.75)\n",
        "    iqr = q3 - q1\n",
        "    lower_bound = q1 - (1.5 * iqr)\n",
        "    upper_bound = q3 + (1.5 * iqr)\n",
        "    \n",
        "    # Identify and plot outliers\n",
        "    is_outlier = (df[col] < lower_bound) | (df[col] > upper_bound)\n",
        "    sns.scatterplot(x=df.index, y=df[col], \n",
        "                    hue=is_outlier, \n",
        "                    palette={False: 'blue', True: 'red'},\n",
        "                    ax=ax)\n",
        "    \n",
        "    # Add IQR reference lines\n",
        "    ax.axhline(y=lower_bound, color='orange', linestyle='--', alpha=0.7)\n",
        "    ax.axhline(y=upper_bound, color='orange', linestyle='--', alpha=0.7)\n",
        "    \n",
        "    # Formatting\n",
        "    ax.set_title(f'Outliers in {col} (IQR Method)', pad=10)\n",
        "    ax.set_ylabel('Value')\n",
        "    ax.legend(['Normal', 'Outlier', 'IQR Threshold'])\n",
        "    \n",
        "plt.tight_layout(pad=2.0)\n",
        "plt.suptitle('Outlier Detection by Column (IQR Method)', y=1.02, fontsize=14)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'venv_name' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: '\"c:/Users/USER/Desktop/Thesis Folder/Ronnie/venv_name/Scripts/python.exe\" -m pip install ipykernel -U --force-reinstall'"
          ]
        }
      ],
      "source": [
        "def remove_outliers_iqr(df, columns):\n",
        "    original_rows = df.shape[0]\n",
        "    \n",
        "    # Compute IQR for specified columns\n",
        "    Q1 = df[columns].quantile(0.25)\n",
        "    Q3 = df[columns].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    \n",
        "    # Define bounds for outliers\n",
        "    lower_bound = Q1 - 1.5 * IQR\n",
        "    upper_bound = Q3 + 1.5 * IQR\n",
        "    \n",
        "    # Filter out outliers\n",
        "    df_cleaned = df[~((df[columns] < lower_bound) | (df[columns] > upper_bound)).any(axis=1)]\n",
        "    cleaned_rows = df_cleaned.shape[0]\n",
        "    rows_removed = original_rows - cleaned_rows\n",
        "    removal_percentage = (rows_removed / original_rows) * 100\n",
        "    \n",
        "    # Print cleaning report\n",
        "    print(\"Cleaning Report:\")\n",
        "    print(f\"Original rows: {original_rows}\")\n",
        "    print(f\"Cleaned rows: {cleaned_rows}\")\n",
        "    print(f\"Rows removed: {rows_removed} ({removal_percentage:.2f}%)\")\n",
        "    \n",
        "    return df_cleaned\n",
        "\n",
        "numeric_columns = df.select_dtypes(include=[np.number]).columns  # Select numerical columns\n",
        "df_cleaned = remove_outliers_iqr(df, numeric_columns)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'venv_name' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: '\"c:/Users/USER/Desktop/Thesis Folder/Ronnie/venv_name/Scripts/python.exe\" -m pip install ipykernel -U --force-reinstall'"
          ]
        }
      ],
      "source": [
        "df = df_cleaned.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'venv_name' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: '\"c:/Users/USER/Desktop/Thesis Folder/Ronnie/venv_name/Scripts/python.exe\" -m pip install ipykernel -U --force-reinstall'"
          ]
        }
      ],
      "source": [
        "df['change_detection_value'] = pd.to_numeric(df['change_detection_value']).astype('Int64')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CUm4L0EIHiGc"
      },
      "source": [
        "<a id=\"setup\"></a>\n",
        "# <p style=\"background-color:rgb(64, 96, 143); font-family:calibri; color:white; font-size:50%; font-family:Verdana; text-align:center; border-radius:5px 5px;\">Step 4 | EXPLORATORY DATA ANALYSIS</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "bLUPR-N1zF9b",
        "outputId": "18f7a3a4-b817-4e20-c573-a3a825e2cfbb"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'venv_name' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: '\"c:/Users/USER/Desktop/Thesis Folder/Ronnie/venv_name/Scripts/python.exe\" -m pip install ipykernel -U --force-reinstall'"
          ]
        }
      ],
      "source": [
        "# Select only numerical columns for correlation\n",
        "numerical_df = df.select_dtypes(include=['float64', 'int64'])\n",
        "\n",
        "# Create correlation matrix\n",
        "corr_matrix = numerical_df.corr()\n",
        "\n",
        "# Generate heatmap\n",
        "plt.figure(figsize=(10, 10))\n",
        "heatmap = sns.heatmap(\n",
        "    corr_matrix, \n",
        "    annot=True, \n",
        "    fmt=\".2f\",  # Show 2 decimal places\n",
        "    cmap='coolwarm',  # Color scheme\n",
        "    center=0,  # Center color at 0\n",
        "    square=True,  # Make cells square\n",
        "    linewidths=.5,  # Add lines between cells\n",
        "    cbar_kws={\"shrink\": 0.8}  # Adjust colorbar size\n",
        ")\n",
        "\n",
        "# Improve readability\n",
        "plt.title('Correlation Heatmap (Numerical Columns Only)', pad=20)\n",
        "heatmap.set_xticklabels(\n",
        "    heatmap.get_xticklabels(),\n",
        "    rotation=45,\n",
        "    horizontalalignment='right'\n",
        ")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div style=\"border-radius:10px; padding: 15px; background-color: rgb(142, 183, 190); \n",
        "            font-size:110%; text-align:LEFT; width: 95%; color: BLACK;\">\n",
        "\n",
        "\n",
        "## Key Observations\n",
        "\n",
        "### 1. Strong Negative Correlations\n",
        "- **Elevation ↔ X-coordinate (-0.96)**  \n",
        "  Indicates higher elevations are associated with decreasing X-values (likely western geographic locations)\n",
        "\n",
        "- **Distance_to_Road ↔ Persons_per_Pixel (-0.38)**  \n",
        "  Suggests populated areas tend to be closer to roads\n",
        "\n",
        "### 2. Moderate Positive Correlations\n",
        "- **Y-coordinate ↔ Distance_to_Airport (0.40)**  \n",
        "  Northern locations (higher Y-values) are typically farther from airports\n",
        "\n",
        "- **Change_Detection_Value ↔ X-coordinate (0.31)**  \n",
        "  Potential regional pattern in land-use changes\n",
        "\n",
        "### 3. Weak/No Correlations\n",
        "- **Slope** shows minimal correlation with all variables  \n",
        "- **Distance_to_Urban_Areas** appears independent of other features\n",
        "\n",
        "### 4. Multicollinearity Warning\n",
        "- **Elevation ↔ X-coordinate (-0.96)**  \n",
        "  Extreme correlation may require remediation for regression modeling:\n",
        "  - Consider removing one feature\n",
        "  - Apply PCA\n",
        "  - Use regularization techniques\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'venv_name' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: '\"c:/Users/USER/Desktop/Thesis Folder/Ronnie/venv_name/Scripts/python.exe\" -m pip install ipykernel -U --force-reinstall'"
          ]
        }
      ],
      "source": [
        "\n",
        "# Calculate map center\n",
        "mean_lat = df['y'].mean()\n",
        "mean_lon = df['x'].mean()\n",
        "\n",
        "# Create base map\n",
        "m = folium.Map(location=[mean_lat, mean_lon], zoom_start=12.1)\n",
        "\n",
        "# Add points with hollow circles\n",
        "for idx, row in df.iterrows():\n",
        "    color = 'green' if row['change_detection_value'] == 1 else 'red'\n",
        "    folium.CircleMarker(\n",
        "        location=[row['y'], row['x']],\n",
        "        radius=2,\n",
        "        color=color,\n",
        "        fill=False,  \n",
        "        weight=2,    # Border thickness\n",
        "        popup=f\"Change: {'Yes' if row['change_detection_value'] == 1 else 'No'}<br>\"\n",
        "              f\"Coordinates: ({row['y']:.6f}, {row['x']:.6f})\"\n",
        "    ).add_to(m)\n",
        "\n",
        "# Add legend\n",
        "legend_html = '''\n",
        "     <div style=\"position: fixed; \n",
        "                 bottom: 50px; left: 50px; width: 150px; height: 80px; \n",
        "                 border:2px solid grey; z-index:9999; font-size:14px;\n",
        "                 background-color:white;\n",
        "                 \">\n",
        "     &nbsp; <strong>Legend</strong> <br>\n",
        "     &nbsp; <span style=\"color:green\">⬤</span> Change (1)<br>\n",
        "     &nbsp; <span style=\"color:red\">⬤</span> No Change (0)\n",
        "     </div>\n",
        "'''\n",
        "m.get_root().html.add_child(folium.Element(legend_html))\n",
        "m.save('coordinate_visualization.html')\n",
        "# Display map\n",
        "m"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ">> After Feature Importance consider dropping Elevation since it is highly correlated with X and X is paramount in our modelling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YZgBSvbcrrC3"
      },
      "source": [
        "<a id=\"setup\"></a>\n",
        "# <p style=\"background-color:rgb(64, 96, 143); font-family:calibri; color:white; font-size:50%; font-family:Verdana; text-align:center; border-radius:5px 5px;\">Step 5 | FEATURE SELECTION</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'venv_name' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: '\"c:/Users/USER/Desktop/Thesis Folder/Ronnie/venv_name/Scripts/python.exe\" -m pip install ipykernel -U --force-reinstall'"
          ]
        }
      ],
      "source": [
        "df.Airport_Name.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'venv_name' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: '\"c:/Users/USER/Desktop/Thesis Folder/Ronnie/venv_name/Scripts/python.exe\" -m pip install ipykernel -U --force-reinstall'"
          ]
        }
      ],
      "source": [
        "df['Airport_Name'] = df['Airport_Name'].apply(lambda x: 1 if x == 'Wilson Airport' else 0)\n",
        "\n",
        "#Observe the change\n",
        "df[\"Airport_Name\"].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SYsUouM7GyGM",
        "outputId": "165782da-d9e3-49a2-85e7-3bc30496c6c2"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'venv_name' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: '\"c:/Users/USER/Desktop/Thesis Folder/Ronnie/venv_name/Scripts/python.exe\" -m pip install ipykernel -U --force-reinstall'"
          ]
        }
      ],
      "source": [
        "#Use Random Forest to get feature importance\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "df_copy = df\n",
        "\n",
        "# Separate the target variable from the features\n",
        "X = df_copy.drop('change_detection_value', axis=1)\n",
        "y = df_copy['change_detection_value']\n",
        "\n",
        "#Split your train and test data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "#Initiate model\n",
        "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "\n",
        "#Train model\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "#Measure feature Importances\n",
        "importances = rf.feature_importances_\n",
        "\n",
        "\n",
        "feature_names = X_train.columns\n",
        "importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': importances})\n",
        "importance_df = importance_df.sort_values(by=\"Importance\", ascending=False)\n",
        "\n",
        "importance_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'venv_name' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: '\"c:/Users/USER/Desktop/Thesis Folder/Ronnie/venv_name/Scripts/python.exe\" -m pip install ipykernel -U --force-reinstall'"
          ]
        }
      ],
      "source": [
        "# List of features to drop\n",
        "features_to_drop = [\n",
        "    'Elevation',\n",
        "    'Slope', \n",
        "    'persons per  pixel 1km2',\n",
        "    'Airport_Name'  # Extremely low importance (0.000539)\n",
        "]\n",
        "\n",
        "# Create new DataFrame without these features\n",
        "df_filtered = df.drop(columns=features_to_drop)\n",
        "\n",
        "# Verify the remaining columns\n",
        "print(\"Remaining features:\")\n",
        "df_filtered.columns.tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'venv_name' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: '\"c:/Users/USER/Desktop/Thesis Folder/Ronnie/venv_name/Scripts/python.exe\" -m pip install ipykernel -U --force-reinstall'"
          ]
        }
      ],
      "source": [
        "df = df_filtered.copy()\n",
        "\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"setup\"></a>\n",
        "# <p style=\"background-color:rgb(64, 96, 143); font-family:calibri; color:white; font-size:50%; font-family:Verdana; text-align:center; border-radius:5px 5px;\">Step 6 | MODELLING</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'venv_name' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: '\"c:/Users/USER/Desktop/Thesis Folder/Ronnie/venv_name/Scripts/python.exe\" -m pip install ipykernel -U --force-reinstall'"
          ]
        }
      ],
      "source": [
        "\n",
        "# Separate features by type\n",
        "coordinates = df[['x', 'y']]  # Geographic coordinates (preserve spatial relationships)\n",
        "distance_features = df.filter(regex='Distance_to_')  # All distance columns\n",
        "binary_target = df['change_detection_value']  # Binary target \n",
        "\n",
        "# 1. Scale coordinates using RobustScaler (preserves spatial relationships)\n",
        "coord_scaler = RobustScaler()\n",
        "scaled_coords = pd.DataFrame(coord_scaler.fit_transform(coordinates), \n",
        "                             columns=['x_scaled', 'y_scaled'],\n",
        "                             index=df.index)\n",
        "\n",
        "# Save the coordinate scaler\n",
        "joblib.dump(coord_scaler, 'coord_scaler.joblib')\n",
        "\n",
        "# 2. Scale distance features using StandardScaler\n",
        "dist_scaler = StandardScaler()\n",
        "scaled_distances = pd.DataFrame(dist_scaler.fit_transform(distance_features), \n",
        "                                columns=[f'scaled_{col}' for col in distance_features.columns],\n",
        "                                index=df.index)\n",
        "\n",
        "# Save the distance scaler\n",
        "joblib.dump(dist_scaler, 'dist_scaler.joblib')\n",
        "\n",
        "# 3. Combine scaled features with original binary target\n",
        "scaled_df = pd.concat([\n",
        "    scaled_coords,\n",
        "    scaled_distances,\n",
        "    binary_target\n",
        "], axis=1)\n",
        "\n",
        "print(\"Scaled Dataset Preview:\")\n",
        "scaled_df.head()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WAoMZRu_uve0"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'venv_name' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: '\"c:/Users/USER/Desktop/Thesis Folder/Ronnie/venv_name/Scripts/python.exe\" -m pip install ipykernel -U --force-reinstall'"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# Separate the target variable from the features\n",
        "X = scaled_df.drop('change_detection_value', axis=1)\n",
        "y = scaled_df['change_detection_value']\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TSa66884BQNV",
        "outputId": "0c78bd22-c999-45eb-a6d6-ef6e13f655bb"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'venv_name' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: '\"c:/Users/USER/Desktop/Thesis Folder/Ronnie/venv_name/Scripts/python.exe\" -m pip install ipykernel -U --force-reinstall'"
          ]
        }
      ],
      "source": [
        "# Check class imbalance first, to be sure\n",
        "from collections import Counter\n",
        "\n",
        "print(\"Original class distribution:\", Counter(y_train))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bwvRUDTrW8hr",
        "outputId": "209530f2-619f-4c22-c2ff-c1deeacdcb4b"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'venv_name' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: '\"c:/Users/USER/Desktop/Thesis Folder/Ronnie/venv_name/Scripts/python.exe\" -m pip install ipykernel -U --force-reinstall'"
          ]
        }
      ],
      "source": [
        "\n",
        "# Apply SMOTETomek to balance classes in training set\n",
        "smote_tomek = SMOTETomek(sampling_strategy='auto', random_state=42)\n",
        "X_train_resampled_smtk, y_train_resampled_smtk = smote_tomek.fit_resample(X_train, y_train)\n",
        "\n",
        "# Check the original and new distribution\n",
        "print(\"Original class distribution:\", Counter(y_train))\n",
        "print(\"Resampled class distribution:\", Counter(y_train_resampled_smtk))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q-mqF4j1LAhm"
      },
      "source": [
        "<a id=\"setup\"></a>\n",
        "# <p style=\"background-color:rgb(64, 96, 143); font-family:calibri; color:white; font-size:50%; font-family:Verdana; text-align:center; border-radius:5px 5px;\">Step 6.1 | Random Forest</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SRRyVmgk_7ps",
        "outputId": "9ec4868d-e35c-413e-92eb-d4900e021407"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'venv_name' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: '\"c:/Users/USER/Desktop/Thesis Folder/Ronnie/venv_name/Scripts/python.exe\" -m pip install ipykernel -U --force-reinstall'"
          ]
        }
      ],
      "source": [
        "# Initialize the model\n",
        "rf = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Fit the model\n",
        "rf.fit(X_train_resampled_smtk, y_train_resampled_smtk)\n",
        "\n",
        "# Generate predictions\n",
        "y_pred = rf.predict(X_test)\n",
        "\n",
        "# Print classification report\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Generate and display confusion matrix\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(cm)\n",
        "\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
        "            xticklabels=['Predicted 0', 'Predicted 1'], \n",
        "            yticklabels=['Actual 0', 'Actual 1'])\n",
        "plt.xlabel('Predicted label')\n",
        "plt.ylabel('True label')\n",
        "plt.title('Confusion Matrix Random Forest Base Model')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"setup\"></a>\n",
        "# <p style=\"background-color:rgb(64, 96, 143); font-family:calibri; color:white; font-size:50%; font-family:Verdana; text-align:center; border-radius:5px 5px;\">Step 6.1.2| Random Forest with RandomizedSearchCV</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MGcPYhf8AQcD"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'venv_name' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: '\"c:/Users/USER/Desktop/Thesis Folder/Ronnie/venv_name/Scripts/python.exe\" -m pip install ipykernel -U --force-reinstall'"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# Initialize the model\n",
        "rf = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Define the parameter grid\n",
        "param_dist = {\n",
        "    'n_estimators': [100, 200, 300],     \n",
        "    'max_depth': [10, 20, None],          \n",
        "    'max_features': ['auto', 'sqrt', 'log2'],  \n",
        "    'bootstrap': [True, False],           \n",
        "    'criterion': ['gini', 'entropy']      \n",
        "}\n",
        "\n",
        "# Set up the Randomized Search with cross-validation\n",
        "random_search = RandomizedSearchCV(estimator=rf,\n",
        "                                 param_distributions=param_dist,\n",
        "                                 n_iter=10,  \n",
        "                                 scoring='recall',\n",
        "                                 cv=5,     \n",
        "                                 random_state=42,\n",
        "                                 n_jobs=-1,  \n",
        "                                 verbose=2)\n",
        "\n",
        "# Fit the tuned model\n",
        "random_search.fit(X_train_resampled_smtk, y_train_resampled_smtk)\n",
        "\n",
        "# Print best parameters\n",
        "print(\"Best parameters found: \", random_search.best_params_)\n",
        "print(\"Best recall score: \", random_search.best_score_)\n",
        "\n",
        "# Get the best estimator\n",
        "best_rf = random_search.best_estimator_\n",
        "\n",
        "# Make predictions on test set\n",
        "y_pred = best_rf.predict(X_test)\n",
        "\n",
        "# Generate classification report\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Generate and display confusion matrix\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(cm)\n",
        "\n",
        "# Visualize confusion matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
        "            xticklabels=['Predicted Negative', 'Predicted Positive'], \n",
        "            yticklabels=['Actual Negative', 'Actual Positive'])\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title('Confusion Matrix - Random Forest (Optimized)')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"setup\"></a>\n",
        "# <p style=\"background-color:rgb(64, 96, 143); font-family:calibri; color:white; font-size:50%; font-family:Verdana; text-align:center; border-radius:5px 5px;\">Step 6.2| Logistic Regression</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'venv_name' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: '\"c:/Users/USER/Desktop/Thesis Folder/Ronnie/venv_name/Scripts/python.exe\" -m pip install ipykernel -U --force-reinstall'"
          ]
        }
      ],
      "source": [
        "\n",
        "# Initialize the model\n",
        "logreg = LogisticRegression(random_state=42, max_iter=1000)\n",
        "\n",
        "# Define the parameter grid for Logistic Regression\n",
        "param_dist = {\n",
        "    'penalty': ['l1', 'l2', 'elasticnet', None],  \n",
        "    'C': loguniform(1e-4, 100),                  \n",
        "    'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'], \n",
        "    'class_weight': [None, 'balanced'],         \n",
        "    'l1_ratio': [0, 0.25, 0.5, 0.75, 1]         \n",
        "}\n",
        "\n",
        "# Set up RandomizedSearchCV with recall scoring\n",
        "random_search = RandomizedSearchCV(\n",
        "    estimator=logreg,\n",
        "    param_distributions=param_dist,\n",
        "    n_iter=20,               \n",
        "    scoring='recall',         \n",
        "    cv=5,                     \n",
        "    random_state=42,\n",
        "    n_jobs=-1,                \n",
        "    verbose=2\n",
        ")\n",
        "\n",
        "# Fit the tuned model\n",
        "random_search.fit(X_train_resampled_smtk, y_train_resampled_smtk)\n",
        "\n",
        "# Print best parameters and score\n",
        "print(\"\\nBest parameters found: \", random_search.best_params_)\n",
        "print(\"Best recall score (CV): \", random_search.best_score_)\n",
        "\n",
        "# Get the best estimator\n",
        "best_logreg = random_search.best_estimator_\n",
        "\n",
        "# Make predictions\n",
        "y_pred = best_logreg.predict(X_test)\n",
        "y_pred_proba = best_logreg.predict_proba(X_test)[:, 1]  # Probability scores for ROC curve\n",
        "\n",
        "# Classification Report\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Confusion Matrix (Numerical)\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(cm)\n",
        "\n",
        "# Confusion Matrix (Visual)\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=['Predicted Negative', 'Predicted Positive'],\n",
        "            yticklabels=['Actual Negative', 'Actual Positive'])\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title('Confusion Matrix - Logistic Regression (Optimized)')\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"setup\"></a>\n",
        "# <p style=\"background-color:rgb(64, 96, 143); font-family:calibri; color:white; font-size:50%; font-family:Verdana; text-align:center; border-radius:5px 5px;\">Step 6.3| XGBoost</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'venv_name' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: '\"c:/Users/USER/Desktop/Thesis Folder/Ronnie/venv_name/Scripts/python.exe\" -m pip install ipykernel -U --force-reinstall'"
          ]
        }
      ],
      "source": [
        "\n",
        "# Initialize XGBoost model\n",
        "xgb = XGBClassifier(random_state=42, eval_metric='logloss', use_label_encoder=False)\n",
        "\n",
        "# Define parameter grid for XGBoost\n",
        "param_dist = {\n",
        "    'n_estimators': [100, 200, 300, 400],       \n",
        "    'max_depth': [3, 5, 7, 9],                  \n",
        "    'learning_rate': [0.01, 0.05, 0.1, 0.2],    \n",
        "    'subsample': [0.6, 0.8, 1.0],               \n",
        "    'colsample_bytree': [0.6, 0.8, 1.0],        \n",
        "    'gamma': [0, 0.1, 0.2],                     \n",
        "    'min_child_weight': [1, 3, 5],              \n",
        "    'scale_pos_weight': [1, (len(y_train_resampled_smtk) - sum(y_train_resampled_smtk)) / sum(y_train_resampled_smtk)]  # Handle class imbalance\n",
        "}\n",
        "\n",
        "# Set up RandomizedSearchCV\n",
        "random_search = RandomizedSearchCV(\n",
        "    estimator=xgb,\n",
        "    param_distributions=param_dist,\n",
        "    n_iter=25,                  \n",
        "    scoring='recall',\n",
        "    cv=5,                       \n",
        "    random_state=42,\n",
        "    n_jobs=-1,\n",
        "    verbose=2\n",
        ")\n",
        "\n",
        "# Fit the model\n",
        "random_search.fit(X_train_resampled_smtk, y_train_resampled_smtk)\n",
        "\n",
        "# Best parameters and score\n",
        "print(\"\\nBest Parameters:\", random_search.best_params_)\n",
        "print(\"Best Recall Score (CV):\", random_search.best_score_)\n",
        "\n",
        "# Get best estimator\n",
        "best_xgb = random_search.best_estimator_\n",
        "\n",
        "# Predictions\n",
        "y_pred = best_xgb.predict(X_test)\n",
        "y_pred_proba = best_xgb.predict_proba(X_test)[:, 1]  # Probabilities for positive class\n",
        "\n",
        "# Classification Report\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Confusion Matrix\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(cm)\n",
        "\n",
        "# Plot Confusion Matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=['Predicted Negative', 'Predicted Positive'],\n",
        "            yticklabels=['Actual Negative', 'Actual Positive'])\n",
        "plt.title('XGBoost Confusion Matrix')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"setup\"></a>\n",
        "# <p style=\"background-color:rgb(64, 96, 143); font-family:calibri; color:white; font-size:50%; font-family:Verdana; text-align:center; border-radius:5px 5px;\">Step 7| Evaluation and Model Selection</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'venv_name' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: '\"c:/Users/USER/Desktop/Thesis Folder/Ronnie/venv_name/Scripts/python.exe\" -m pip install ipykernel -U --force-reinstall'"
          ]
        }
      ],
      "source": [
        "models = {\n",
        "    'Random Forest (Baseline)': rf.fit(X_train_resampled_smtk, y_train_resampled_smtk),\n",
        "    'Random Forest (Optimized)': best_rf.fit(X_train_resampled_smtk, y_train_resampled_smtk),\n",
        "    'Logistic Regression': best_logreg.fit(X_train_resampled_smtk, y_train_resampled_smtk),\n",
        "    'XGBoost': best_xgb.fit(X_train_resampled_smtk, y_train_resampled_smtk)\n",
        "}\n",
        "\n",
        "# Now calculate metrics\n",
        "metrics = []\n",
        "for name, model in models.items():\n",
        "    try:\n",
        "        y_pred = model.predict(X_test)\n",
        "        y_proba = model.predict_proba(X_test)[:, 1] if hasattr(model, \"predict_proba\") else [0]*len(X_test)\n",
        "        \n",
        "        metrics.append({\n",
        "            'Model': name,\n",
        "            'Accuracy': accuracy_score(y_test, y_pred),\n",
        "            'Precision': precision_score(y_test, y_pred),\n",
        "            'Recall': recall_score(y_test, y_pred),\n",
        "            'F1': f1_score(y_test, y_pred),\n",
        "            'ROC AUC': roc_auc_score(y_test, y_proba) if hasattr(model, \"predict_proba\") else None\n",
        "        })\n",
        "    except Exception as e:\n",
        "        print(f\"Error with {name}: {str(e)}\")\n",
        "        metrics.append({\n",
        "            'Model': name,\n",
        "            'Error': str(e)\n",
        "        })\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'venv_name' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: '\"c:/Users/USER/Desktop/Thesis Folder/Ronnie/venv_name/Scripts/python.exe\" -m pip install ipykernel -U --force-reinstall'"
          ]
        }
      ],
      "source": [
        "plt.figure(figsize=(14, 8))\n",
        "plt.title('Model Performance Comparison (Bar Graph)', fontsize=16, pad=20)\n",
        "\n",
        "# Metrics to plot\n",
        "metrics_to_plot = ['Accuracy', 'Precision', 'Recall', 'F1']\n",
        "colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728']  # Distinct colors\n",
        "\n",
        "# Create x-axis positions\n",
        "model_names = [m['Model'] for m in metrics]\n",
        "x = np.arange(len(model_names))\n",
        "width = 0.2  # Width of each bar\n",
        "\n",
        "# Plot each metric as grouped bars\n",
        "for i, metric in enumerate(metrics_to_plot):\n",
        "    values = [m[metric] for m in metrics]\n",
        "    bars = plt.bar(x + i*width, values, width, color=colors[i], label=metric)\n",
        "    \n",
        "    # Add value labels on top of each bar\n",
        "    for bar in bars:\n",
        "        height = bar.get_height()\n",
        "        plt.text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
        "                 f'{height:.2f}',\n",
        "                 ha='center', va='bottom',\n",
        "                 fontsize=10)\n",
        "\n",
        "# Customize plot\n",
        "plt.xticks(x + 1.5*width, model_names, rotation=45, ha='right', fontsize=12)\n",
        "plt.yticks(np.linspace(0, 1.1, 12))\n",
        "plt.xlabel('Machine Learning Models', fontsize=12)\n",
        "plt.ylabel('Performance Score', fontsize=12)\n",
        "plt.ylim(0, 1.2)  # Increased upper limit for value labels\n",
        "plt.grid(True, axis='y', linestyle='--', alpha=0.6)\n",
        "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=12)\n",
        "\n",
        "# Add horizontal reference lines\n",
        "for y in np.arange(0.2, 1.1, 0.2):\n",
        "    plt.axhline(y=y, color='gray', linestyle=':', alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div style=\"border-radius:10px; padding: 15px; background-color: rgb(142, 183, 190); \n",
        "            font-size:110%; text-align:LEFT; width: 95%; color: BLACK;\">\n",
        "\n",
        "### Model Performance Evaluation and Best Model Selection\n",
        "\n",
        "#### **Key Performance Metrics**\n",
        "| Metric               | Random Forest (Baseline) | Random Forest (Optimized) | Logistic Regression | XGBoost |\n",
        "|----------------------|-------------------------|--------------------------|---------------------|---------|\n",
        "| **Accuracy**         | 0.85                   | 0.88                    | 0.77               | 0.88    |\n",
        "| **Precision**        | 0.42                   | 0.45                    | 0.28               | 0.45    |\n",
        "| **Recall**           | 0.63                   | 0.65                    | 0.74               | 0.65    |\n",
        "| **F1 Score**         | 0.50                   | 0.53                    | 0.41               | 0.53    |\n",
        "\n",
        "#### **Model Strengths and Weaknesses**\n",
        "\n",
        "**Random Forest (Optimized)**\n",
        "- ✅ **Highest accuracy** (tied with XGBoost)\n",
        "- ✅ **Best precision/F1 balance**\n",
        "- ❌ Slightly lower recall than Logistic Regression\n",
        "\n",
        "**XGBoost**  \n",
        "- ✅ **Equal best accuracy/precision**\n",
        "- ✅ **Handles class imbalance well**\n",
        "- ❌ More complex to interpret\n",
        "\n",
        "**Logistic Regression**\n",
        "- ✅ **Highest recall** (74%)\n",
        "- ❌ **Lowest precision/F1**\n",
        "- ❌ Significant false positives\n",
        "\n",
        "**Baseline Random Forest**\n",
        "- ✅ Simple implementation\n",
        "- ❌ Underperforms optimized versions\n",
        "\n",
        "#### **Confusion Matrix Insights**\n",
        "\n",
        "| Model                | True Negatives | False Positives | False Negatives | True Positives |\n",
        "|----------------------|---------------|-----------------|-----------------|----------------|\n",
        "| RF (Optimized)       | 1164          | 251             | 55              | 102            |\n",
        "| XGBoost              | 1163          | 252             | 55              | 102            |\n",
        "| Logistic Regression  | 970           | 295             | 41              | 116            |\n",
        "| RF (Baseline)        | 1150          | 265             | 60              | 97             |\n",
        "\n",
        "#### **Recommended Model Selection**\n",
        "\n",
        "1. **For Production Deployment**:\n",
        "   - 🏆 **XGBoost** - Best overall performance\n",
        "   - 🥈 Random Forest (Optimized) - Close second, more interpretable\n",
        "\n",
        "2. **When High Recall is Critical** (e.g., medical diagnosis):\n",
        "   - 🚨 Logistic Regression - Despite lower precision\n",
        "\n",
        "3. **Baseline Reference**:\n",
        "   - 🔍 Random Forest (Baseline) - Demonstrates optimization impact\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'venv_name' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: '\"c:/Users/USER/Desktop/Thesis Folder/Ronnie/venv_name/Scripts/python.exe\" -m pip install ipykernel -U --force-reinstall'"
          ]
        }
      ],
      "source": [
        "XGbest_model = best_xgb.fit(X_train_resampled_smtk, y_train_resampled_smtk)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'venv_name' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: '\"c:/Users/USER/Desktop/Thesis Folder/Ronnie/venv_name/Scripts/python.exe\" -m pip install ipykernel -U --force-reinstall'"
          ]
        }
      ],
      "source": [
        "# Save your already-trained XGBoost model\n",
        "joblib.dump(XGbest_model, 'urban_change_model.joblib')\n",
        "\n",
        "print(\"Model successfully saved as 'urban_change_model.joblib'\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"setup\"></a>\n",
        "# <p style=\"background-color:rgb(64, 96, 143); font-family:calibri; color:white; font-size:50%; font-family:Verdana; text-align:center; border-radius:5px 5px;\">Step 8| Deployment</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'venv_name' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: '\"c:/Users/USER/Desktop/Thesis Folder/Ronnie/venv_name/Scripts/python.exe\" -m pip install ipykernel -U --force-reinstall'"
          ]
        }
      ],
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "\n",
        "# Load model and scalers\n",
        "model = joblib.load('urban_change_model.joblib')\n",
        "coord_scaler = joblib.load('coord_scaler.joblib')\n",
        "dist_scaler = joblib.load('dist_scaler.joblib')\n",
        "\n",
        "def main():\n",
        "    st.set_page_config(page_title=\"Urban Change Predictor\", layout=\"wide\")\n",
        "    \n",
        "    # Custom CSS for background image\n",
        "    st.markdown(\n",
        "        f\"\"\"\n",
        "        <style>\n",
        "            .stApp {{\n",
        "                background: url(\"https://imgix.brilliant-africa.com/Nairobi-National-Park-1.jpg?auto=format,enhance,compress&fit=crop&crop=entropy,faces,focalpoint&w=1880&h=740&q=30\") no-repeat center center fixed;\n",
        "                background-size: cover;\n",
        "            }}\n",
        "        </style>\n",
        "        \"\"\",\n",
        "        unsafe_allow_html=True\n",
        "    )\n",
        "    \n",
        "    st.title(\"🌆 Urban Change Prediction Dashboard\")\n",
        "    \n",
        "    # Input Selection\n",
        "    input_method = st.radio(\"Select Input Method:\", [\"📍 Manual Entry\", \"📁 Upload CSV\"], horizontal=True)\n",
        "    \n",
        "    if input_method == \"📍 Manual Entry\":\n",
        "        col1, col2 = st.columns(2)\n",
        "        \n",
        "        with col1:\n",
        "            x = st.number_input(\"Longitude (x)\", value=36.922205, format=\"%.6f\")\n",
        "            y = st.number_input(\"Latitude (y)\", value=-1.336726, format=\"%.6f\")\n",
        "        \n",
        "        with col2:\n",
        "            road = st.number_input(\"Distance to Road (m)\", value=412.73)\n",
        "            airport = st.number_input(\"Distance to Airport (m)\", value=1987.40)\n",
        "            urban = st.number_input(\"Distance to Urban (m)\", value=10142.31)\n",
        "        \n",
        "        input_df = pd.DataFrame({\n",
        "            'x': [x], 'y': [y],\n",
        "            'Distance_to_Road(Metres)': [road],\n",
        "            'Distance_to_Airport(Metres)': [airport],\n",
        "            'Distance_to_Urban_Areas(Metres)': [urban]\n",
        "        })\n",
        "    else:\n",
        "        uploaded_file = st.file_uploader(\"Upload CSV File\", type=[\"csv\"])\n",
        "        if uploaded_file:\n",
        "            input_df = pd.read_csv(uploaded_file)\n",
        "            st.dataframe(input_df.head(3))\n",
        "    \n",
        "    if st.button(\"🚀 Predict\") and 'input_df' in locals():\n",
        "        with st.spinner(\"Analyzing... Please wait.\"):\n",
        "            # Scale features\n",
        "            coords = coord_scaler.transform(input_df[['x', 'y']])\n",
        "            dists = dist_scaler.transform(input_df.filter(regex='Distance_to_'))\n",
        "            X = np.hstack([coords, dists])\n",
        "            \n",
        "            # Make predictions\n",
        "            preds = model.predict(X)\n",
        "            probas = model.predict_proba(X)[:, 1]  # Probability of Urban Change\n",
        "            \n",
        "            # Format results\n",
        "            results = input_df.copy()\n",
        "            results['Prediction'] = np.where(preds == 1, 'Urban Change', 'No Change')\n",
        "            results['Probability'] = [f\"{p:.1%}\" for p in probas]\n",
        "            results['Confidence'] = np.select(\n",
        "                [probas > 0.7, probas > 0.4],\n",
        "                ['High', 'Medium'],\n",
        "                default='Low'\n",
        "            )\n",
        "            \n",
        "            st.success(\"✅ Prediction Complete!\")\n",
        "            \n",
        "            # Apply styling\n",
        "            def highlight_urban_change(row):\n",
        "                return ['background-color: #90EE90' if row['Prediction'] == 'Urban Change' else ''] * len(row)\n",
        "            \n",
        "            st.dataframe(\n",
        "                results.style\n",
        "                .apply(highlight_urban_change, axis=1)\n",
        "                .format({\n",
        "                    'x': '{:.6f}', 'y': '{:.6f}',\n",
        "                    'Distance_to_Road(Metres)': '{:.2f}',\n",
        "                    'Distance_to_Airport(Metres)': '{:.2f}',\n",
        "                    'Distance_to_Urban_Areas(Metres)': '{:.2f}'\n",
        "                })\n",
        "            )\n",
        "            \n",
        "            # Download button\n",
        "            csv = results.to_csv(index=False).encode('utf-8')\n",
        "            st.download_button(\"💾 Download Results\", csv, \"urban_change_predictions.csv\", \"text/csv\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "4N9-KXAsLKTw"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "myenv",
      "language": "python",
      "name": "myenv"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
